

---
title: "[review] How I run three ai models in parallel w/o losing my mind"
date: "2025-05-03"
category: "note"
---

https://every.to/working-overtime/how-i-run-three-ai-models-in-parallel-without-losing-my-mind


I was shared this article from slack channel compayny's community of AI working. I woke up alert firing and opened my laptop to dientify  what the issue is. I wasn't in charge of on call that week, but It's the best way to save entire efforts. After the investigation, I found this article from the channel. It made me keep wake up until sun rise. 

This first thing what I suprise is that the author has great writing skill attracting reader to the subject she wants to share. she mentioned over-cook, the video game cooking with other people or programmed players. This start can make soft landing before insisting her opinion strengthen itself


Main subject of this article is about how to manage schedule of running many models at the same time. There were schedules for makers and managers which are much different comparing each others. By using multiple model on businesses, we have to adjust schedule of model manager, even if we're the maker. she said. 


she got reach some lessons to manage models efficiently. 


--------
>I’ve found that keep the overhead manageable:

Compartmentalize rigorously. Separate chats for each project, so context waits where I left it and I don’t get work streams confused.

Leave breadcrumbs. Before I pivot to a new task, I drop a one-line note in the chat window about what comes next, so it’s easier to pick up where I left off.

Limit active tasks. Never have more than three things spinning at once; beyond that, the re-entry tax gets brutal.

Capture immediately. When something reaches a usable state, I transplant it to a permanent home (typically a Google Doc) immediately. Leave it floating in the chat and it's lost.

The switching costs never disappear. But with these boundaries, I can keep the operation running instead of drowning in my own clever parallel processing scheme.

--------




